{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709a279d",
   "metadata": {},
   "source": [
    "## Pseudo-labing\n",
    "\n",
    "The goal of this python file is to get a dataset that is a merge of both the two datasets that we have and use it to train our model.\n",
    "\n",
    "We have:\n",
    "* Dataset A → images + age + gender + race\n",
    "* Dataset B → images + emotion only\n",
    "\n",
    "We want to:\n",
    "1. Train a demographics model on Dataset A\n",
    "2. Use it to predict age/gender/race on Dataset B\n",
    "3. Save those predictions as pseudo-labels with confidence\n",
    "4. Merge the datasets safely\n",
    "\n",
    "This is called **pseudo-labeling**\n",
    "\n",
    "Important: these are not true labels, so we store them separately and track confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba82e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renubandaru/Code/GitHub/facial-profiler/deeplearning/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48081a",
   "metadata": {},
   "source": [
    "### STEP 1 -Load Dataset A and Dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cba62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path  age  gender  Race\n",
      "0  source_data/UTK-Face/part3/27_0_1_201701201338...   27       0     1\n",
      "1  source_data/UTK-Face/part3/24_0_3_201701191655...   24       0     3\n",
      "2  source_data/UTK-Face/part3/8_1_0_2017011715460...    8       1     0\n",
      "3  source_data/UTK-Face/part3/85_1_0_201701202226...   85       1     0\n",
      "4  source_data/UTK-Face/part3/26_1_0_201701191929...   26       1     0\n",
      "                                          image_path  emotion\n",
      "0  source_data/raf/DATASET/train/7/train_11651_al...        7\n",
      "1  source_data/raf/DATASET/train/7/train_10043_al...        7\n",
      "2  source_data/raf/DATASET/train/7/train_11301_al...        7\n",
      "3  source_data/raf/DATASET/train/7/train_10513_al...        7\n",
      "4  source_data/raf/DATASET/train/7/train_11148_al...        7\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "dfA = pd.read_csv(\"utk_face_labels.csv\")   # age, gender, race\n",
    "dfB = pd.read_csv(\"raf_labels.csv\")   # emotion only\n",
    "\n",
    "print(dfA.head())\n",
    "print(dfB.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebffbd",
   "metadata": {},
   "source": [
    "### STEP 2 — Convert Age to Bins\n",
    "\n",
    "We are doing this step because the exact age prediction is noisy and difficult. Age classificiation into bins is more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2e748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique age bins in dfA: [2 0 6 5 3 4 1]\n",
      "   age  age_bin\n",
      "0   27        2\n",
      "1   24        2\n",
      "2    8        0\n",
      "3   85        6\n",
      "4   26        2\n",
      "5   57        5\n",
      "6   33        3\n",
      "7   78        6\n",
      "8   45        4\n",
      "9   34        3\n"
     ]
    }
   ],
   "source": [
    "# Create age bins\n",
    "age_bins = [0,10,20,30,40,50,60,200]\n",
    "\n",
    "def age_to_bin(age):\n",
    "    return np.digitize(age, age_bins) - 1\n",
    "\n",
    "# Convert age to bins and add as a new column in dfA\n",
    "dfA[\"age_bin\"] = dfA[\"age\"].apply(age_to_bin)\n",
    "\n",
    "# printing the unique age bins to verify\n",
    "print(\"Unique age bins in dfA:\", dfA[\"age_bin\"].unique())\n",
    "\n",
    "print(dfA[[\"age\", \"age_bin\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e02c59",
   "metadata": {},
   "source": [
    "### STEP 3 — Converting Gender to Integers\n",
    "\n",
    "Neural networks need numeric labels. Therefore we need to convert them accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d4191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original dataset shape: (24102, 5)\n",
      "Dataset shape after dropping gender=3: (24102, 5)\n",
      "Number of age bins: 7\n",
      "Number of gender classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where gender class is 3 since its meaning is unclear and it may be an outlier or error in the dataset\n",
    "print(f\"\\nOriginal dataset shape: {dfA.shape}\")\n",
    "dfA = dfA[dfA['gender'] != 3]\n",
    "print(f\"Dataset shape after dropping gender=3: {dfA.shape}\")\n",
    "\n",
    "# Convert gender to categorical if it's not already numeric\n",
    "if dfA[\"gender\"].dtype == \"object\":\n",
    "    dfA[\"gender\"] = dfA[\"gender\"].astype(\"category\").cat.codes\n",
    "\n",
    "num_age = dfA[\"age_bin\"].nunique()\n",
    "num_gender = dfA[\"gender\"].nunique()\n",
    "\n",
    "print(f\"Number of age bins: {num_age}\")\n",
    "print(f\"Number of gender classes: {num_gender}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacaa9c3",
   "metadata": {},
   "source": [
    "### STEP 4 — Train/Validation Split\n",
    "\n",
    "Both shuffle=True and stratify=dfA[\"age_bin\"] are important for proper model training and evaluation. \n",
    "\n",
    "* Benefits of shuffle=True:\n",
    "    - Prevents order bias: Without shuffling, if your data is sorted by age, the model might learn patterns based on the order rather than actual features\n",
    "    - Better generalization: Random mixing ensures the model sees diverse examples in each batch\n",
    "    - Prevents overfitting to data patterns: Shuffling breaks any inherent ordering that might exist in your dataset\n",
    "\n",
    "* Benefits of stratify=dfA[\"age_bin\"]:\n",
    "    - Balanced age distribution: Ensures both training and validation sets have the same proportion of each age group\n",
    "    - Prevents bias: Without stratification, some age groups might be underrepresented in validation, leading to unreliable performance metrics\n",
    "    - More accurate evaluation: Your validation set will better represent the real-world age distribution\n",
    "    - Stable training: Prevents scenarios where certain age groups are only in training or only in validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ff01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split for dataset A with stratification on age bins\n",
    "trainA, valA = train_test_split(\n",
    "    dfA,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=dfA[\"age_bin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad984857",
   "metadata": {},
   "source": [
    "### STEP 5 — Create TensorFlow Data Pipeline\n",
    "\n",
    "TensorFlow works best with tf.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bf0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Tensforflow dataset for training\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Function to preprocess images to a standard size and normalize pixel values\n",
    "def preprocess_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# Build the dataset - Dataset A Loader:\n",
    "\n",
    "def create_datasetA(df, training=True):\n",
    "    image_paths = df[\"image_path\"].values\n",
    "    age = df[\"age_bin\"].values\n",
    "    gender = df[\"gender\"].values\n",
    "    \n",
    "    # Create a TensorFlow dataset from the image paths and labels\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, age, gender))\n",
    "\n",
    "    # Map the dataset to load and preprocess images and return labels\n",
    "    def load_data(path,age,gender) :\n",
    "        img = preprocess_image(path)\n",
    "        return img, {\n",
    "            \"age\": age,\n",
    "            \"gender\": gender\n",
    "        }\n",
    "    \n",
    "    # Map the dataset to load and preprocess images and return labels\n",
    "    ds = ds.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_ds = create_datasetA(trainA, training=True)\n",
    "val_ds = create_datasetA(valA, training=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb7b50",
   "metadata": {},
   "source": [
    "### STEP 6 — Build Multi-Output Model\n",
    "\n",
    "This is a very important step\n",
    "\n",
    "We use:\n",
    "- Pretrained MobileNetV2\n",
    "- 2 output heads:\n",
    "    - age\n",
    "    - gender\n",
    "Shared feature extractor → multiple tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c12d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model - MobileNetV2 as the base model for feature extraction\n",
    "base_mode = keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "\n",
    "base_mode.trainable = False  # Freeze the base model first\n",
    "\n",
    "# Add custom layers on top of the base model for age and gender\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_mode(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Output layers for age and gender\n",
    "age_output = layers.Dense(num_age, activation=\"softmax\", name=\"age\")(x)\n",
    "gender_output = layers.Dense(num_gender, activation=\"softmax\", name=\"gender\")(x)\n",
    "\n",
    "# Create the model with two outputs\n",
    "model = keras.Model(inputs=inputs, outputs=[age_output, gender_output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059582a1",
   "metadata": {},
   "source": [
    "### STEP 7 — Compile Model (Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e17204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss={\n",
    "        \"age\": keras.losses.SparseCategoricalCrossentropy(),\n",
    "        \"gender\": keras.losses.SparseCategoricalCrossentropy()\n",
    "    },\n",
    "    metrics={\n",
    "        \"age\": \"accuracy\",\n",
    "        \"gender\": \"accuracy\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55902e3",
   "metadata": {},
   "source": [
    "### STEP 8 — Train on Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b11284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/603\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 182ms/step - age_accuracy: 0.2517 - age_loss: 1.8930 - gender_accuracy: 0.6237 - gender_loss: 0.6615 - loss: 2.5546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 11:39:59.648703: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/603\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 181ms/step - age_accuracy: 0.2621 - age_loss: 1.8761 - gender_accuracy: 0.6320 - gender_loss: 0.6505 - loss: 2.5266"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e66a51",
   "metadata": {},
   "source": [
    "### STEP 9 — Predict Pseudo-Labels for Dataset B\n",
    "\n",
    "Create loader for B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo-labels for dataset B using the trained model\n",
    "\n",
    "IMG_SIZE = 224  # must match model input size\n",
    "\n",
    "# Function to load and preprocess images for dataset B\n",
    "def load_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    img = keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Create a TensorFlow dataset for dataset B\n",
    "def create_datasetB(df):\n",
    "    image_paths = df[\"image_path\"].values\n",
    "    \n",
    "    # Create a TensorFlow dataset from the image paths\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths))\n",
    "\n",
    "    # Map the dataset to load and preprocess images\n",
    "    def process(path) :\n",
    "        img = load_image(path)\n",
    "        return img, path\n",
    "    \n",
    "    # Map the dataset to load and preprocess images and return labels\n",
    "    ds = ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Prefetch for performance\n",
    "    return ds\n",
    "\n",
    "\n",
    "dsB = create_datasetB(dfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b74ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 23:52:46.980177: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Generate pseudo-labels predictions for dataset B using the trained model\n",
    "\n",
    "# Store predictions and confidence scores\n",
    "age_preds = []\n",
    "gender_preds = []\n",
    "\n",
    "age_conf = []\n",
    "gender_conf = []\n",
    "\n",
    "# Iterate through dataset B and get predictions from the model\n",
    "for images, paths in dsB:\n",
    "    age_p, gender_p = model.predict(images, verbose=0)\n",
    "    \n",
    "    age_preds.extend(np.argmax(age_p, axis=1))\n",
    "    gender_preds.extend(np.argmax(gender_p, axis=1))\n",
    "    \n",
    "    age_conf.extend(np.max(age_p, axis=1))\n",
    "    gender_conf.extend(np.max(gender_p, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42988332",
   "metadata": {},
   "source": [
    "### STEP 10 — Create Augmented Dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1e88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path  emotion  age_pseudo  \\\n",
      "0  source_data/raf/DATASET/train/7/train_11651_al...        7           4   \n",
      "1  source_data/raf/DATASET/train/7/train_10043_al...        7           1   \n",
      "2  source_data/raf/DATASET/train/7/train_11301_al...        7           2   \n",
      "3  source_data/raf/DATASET/train/7/train_10513_al...        7           5   \n",
      "4  source_data/raf/DATASET/train/7/train_11148_al...        7           2   \n",
      "\n",
      "   gender_pseudo  age_conf  gender_conf  \n",
      "0              1  0.263394     0.504591  \n",
      "1              1  0.512256     0.882156  \n",
      "2              1  0.687731     0.572668  \n",
      "3              1  0.410027     0.861015  \n",
      "4              0  0.552722     0.724074  \n"
     ]
    }
   ],
   "source": [
    "# Add the pseudo-labels and confidence scores to the original dataframe for dataset B\n",
    "dfB[\"age_pseudo\"] = age_preds\n",
    "dfB[\"gender_pseudo\"] = gender_preds\n",
    "\n",
    "dfB[\"age_conf\"] = age_conf\n",
    "dfB[\"gender_conf\"] = gender_conf\n",
    "\n",
    "print(dfB.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c9a86",
   "metadata": {},
   "source": [
    "### STEP 11 — Confidence Filtering\n",
    "\n",
    "We don’t trust low-confidence predictions. Therefore it is necessary for us to drop those predictions\n",
    "\n",
    "* -1 = unknown\n",
    "* Others = pseudo-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.50 # Set a confidence threshold for accepting pseudo-labels\n",
    "\n",
    "# Set pseudo-labels to -1 for samples where confidence is below the threshold\n",
    "dfB.loc[dfB[\"age_conf\"] < THRESHOLD, \"age_pseudo\"] = -1\n",
    "dfB.loc[dfB[\"gender_conf\"] < THRESHOLD, \"gender_pseudo\"] = -1\n",
    "\n",
    "# Save the updated dataframe with pseudo-labels to a new CSV file`\n",
    "dfB.to_csv(\"B_with_pseudo_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04ba86",
   "metadata": {},
   "source": [
    "### STEP 12 — Merge Datasets\n",
    "\n",
    "Keep true vs pseudo separate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_path', 'age', 'gender', 'emotion'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/3n0ncsj14_v1kd3n7lp0spnh0000gn/T/ipykernel_9763/7742082.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfA[\"emotion\"] = -1  # no emotion label in A\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'age_bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/GitHub/facial-profiler/deeplearning/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age_bin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge datasets A and B using the true labels from dataset A and the pseudo-labels from dataset B.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dfA[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# no emotion label in A\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dfA[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdfA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage_bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m        \u001b[38;5;66;03m# true age\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dfA[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dfA[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# true gender\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dfA \u001b[38;5;241m=\u001b[39m dfA[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/Code/GitHub/facial-profiler/deeplearning/lib/python3.9/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Code/GitHub/facial-profiler/deeplearning/lib/python3.9/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age_bin'"
     ]
    }
   ],
   "source": [
    "# Merge datasets A and B using the true labels from dataset A and the pseudo-labels from dataset B.\n",
    "\n",
    "dfA[\"emotion\"] = -1  # no emotion label in A\n",
    "\n",
    "dfA[\"age\"] = dfA[\"age_bin\"]        # true age\n",
    "dfA[\"gender\"] = dfA[\"gender\"]  # true gender\n",
    "\n",
    "dfA = dfA[[\"image_path\", \"age\", \"gender\", \"emotion\"]]\n",
    "\n",
    "\n",
    "# Since dataset B does not have true labels, we will use the pseudo-labels as the \"true\" labels for merging. \n",
    "# We will also keep the original columns for clarity, but they will be filled with NaN since we don't have true labels for dataset B.\n",
    "dfB[\"age\"] = dfB[\"age_pseudo\"]\n",
    "dfB[\"gender\"] = dfB[\"gender_pseudo\"]\n",
    "dfB[\"emotion\"] = dfB[\"emotion\"]\n",
    "\n",
    "dfB = dfB[[\"image_path\", \"age\", \"gender\", \"emotion\"]]\n",
    "\n",
    "# Merge the two datasets\n",
    "merged = pd.concat([dfA, dfB], ignore_index=True)\n",
    "merged.to_csv(\"merged_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77201c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
