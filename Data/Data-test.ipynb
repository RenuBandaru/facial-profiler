{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c2aeb0-d7cc-4f95-b0a9-2bf709ca789d",
   "metadata": {},
   "source": [
    "# Step 0 — Install / imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3ff2a-db0c-43b0-88cf-65a2ca5f1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install torch torchvision pandas numpy pillow scikit-learn tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407a4fe-4981-4641-9b0f-98466ba6b5ea",
   "metadata": {},
   "source": [
    "# Step 1 — Load Your Metadata CSVs\n",
    "\n",
    "You should have (or create) two CSV files:\n",
    "\n",
    "### A.csv  \n",
    "**Columns example:**  \n",
    "image_path, age, gender, race\n",
    "\n",
    "### B.csv  \n",
    "**Columns example:**  \n",
    "image_path, emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595732a3-82bc-47a7-b455-1da60effea74",
   "metadata": {},
   "source": [
    "## Create A.csv and B.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fdd89f-d562-4cc8-9c41-0280da923930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "datasetA_dir = r\"C:\\Users\\bensa\\Desktop\\ETUDES\\Deep Learning\\Project\\UTK-Face\\part1\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fname in os.listdir(datasetA_dir):\n",
    "    if fname.endswith(\".jpg\") or fname.endswith(\".png\"):\n",
    "        \n",
    "        # Remove extension first\n",
    "        name = os.path.splitext(fname)[0]\n",
    "        parts = name.split(\"_\")\n",
    "        \n",
    "        # UTKFace format: age_gender_race_date\n",
    "        if len(parts) >= 3:\n",
    "            try:\n",
    "                age = int(parts[0])\n",
    "                gender = int(parts[1])\n",
    "                race = int(parts[2])\n",
    "\n",
    "                rows.append({\n",
    "                    \"image_path\": os.path.join(datasetA_dir, fname),\n",
    "                    \"age\": age,\n",
    "                    \"gender\": gender,\n",
    "                    \"race\": race\n",
    "                })\n",
    "            except ValueError:\n",
    "                # Skip incorrectly formatted files\n",
    "                continue\n",
    "\n",
    "dfA = pd.DataFrame(rows)\n",
    "dfA.to_csv(\"A.csv\", index=False)\n",
    "\n",
    "print(\"A.csv created\")\n",
    "print(dfA.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac94f9-869f-4df2-8b43-5f6d23d19efe",
   "metadata": {},
   "source": [
    "##  Dataset B already has a CSV \n",
    "Just rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fedb3-c0db-462c-9d5a-6e1e7771ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB = pd.read_csv(r\"C:\\Users\\bensa\\Desktop\\ETUDES\\Deep Learning\\Project\\B.csv\")\n",
    "dfB = dfB.rename(columns={\"emotion_column_name\":\"emotion\",\n",
    "                          \"image_column_name\":\"image_path\"})\n",
    "dfB.to_csv(\"B.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3a3d5-5c63-46ef-b10b-96ac4964f10b",
   "metadata": {},
   "source": [
    "## Important Checks Before Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259b202-4860-4b14-8dd1-7b512830eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Dataset A shape:\", pd.read_csv(\"A.csv\").shape)\n",
    "print(\"Dataset B shape:\", pd.read_csv(\"B.csv\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c418d83-1d71-4964-89de-87fbdbfa8029",
   "metadata": {},
   "source": [
    "Also verify that images load correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b45e38-b3fa-4846-8773-849fcf06bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "sample = pd.read_csv(\"A.csv\").iloc[0][\"image_path\"]\n",
    "Image.open(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabf32c-9bd1-4961-8c9c-e5569d6eabbe",
   "metadata": {},
   "source": [
    "## Load your metadata CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd4fa4-7d7d-40cf-9362-7aed247d2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.read_csv(\"A.csv\")\n",
    "dfB = pd.read_csv(\"B.csv\")\n",
    "\n",
    "print(dfA.head())\n",
    "print(dfB.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f881e-f9cb-44f5-a0d4-be86d27b49ac",
   "metadata": {},
   "source": [
    "## Step 2 — Decide Label Formats (Especially for Age)\n",
    "\n",
    "**Age:** Strongly recommended to use age bins (more stable than exact age).\n",
    "\n",
    "### Example Age Bins:\n",
    "\n",
    "0–9  \n",
    "10–19  \n",
    "20–29  \n",
    "30–39  \n",
    "40–49  \n",
    "50–59  \n",
    "60+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f2ffe-2b88-4338-88ea-049d9b950cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0,10,20,30,40,50,60,200]\n",
    "age_bin_labels = list(range(len(age_bins)-1))  # 0..6\n",
    "\n",
    "def age_to_bin(age):\n",
    "    return int(np.digitize(age, age_bins) - 1)\n",
    "\n",
    "dfA[\"age_bin\"] = dfA[\"age\"].apply(age_to_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489fd19-d928-4af4-ac8d-c481d313c949",
   "metadata": {},
   "source": [
    "For gender and race, you need them as integer class IDs already. If they’re strings, map them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5081f6-70ed-4f17-b1e8-982f5b1d6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example if gender is strings like \"male\"/\"female\"\n",
    "if dfA[\"gender\"].dtype == \"object\":\n",
    "    gender_map = {g:i for i,g in enumerate(sorted(dfA[\"gender\"].unique()))}\n",
    "    dfA[\"gender_id\"] = dfA[\"gender\"].map(gender_map)\n",
    "else:\n",
    "    dfA[\"gender_id\"] = dfA[\"gender\"]\n",
    "\n",
    "# Example if race is strings\n",
    "if dfA[\"race\"].dtype == \"object\":\n",
    "    race_map = {r:i for i,r in enumerate(sorted(dfA[\"race\"].unique()))}\n",
    "    dfA[\"race_id\"] = dfA[\"race\"].map(race_map)\n",
    "else:\n",
    "    dfA[\"race_id\"] = dfA[\"race\"]\n",
    "\n",
    "num_age = dfA[\"age_bin\"].nunique()\n",
    "num_gender = dfA[\"gender_id\"].nunique()\n",
    "num_race = dfA[\"race_id\"].nunique()\n",
    "\n",
    "(num_age, num_gender, num_race)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b42e8-2f1e-4b60-9d38-bbda8c23e1ee",
   "metadata": {},
   "source": [
    "# Step 3 — Build a Dataset + DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9d4b4-ad32-4d1c-8167-1c5e5c802e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, has_demo_labels=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.has_demo_labels = has_demo_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.has_demo_labels:\n",
    "            y_age = int(row[\"age_bin\"])\n",
    "            y_gender = int(row[\"gender_id\"])\n",
    "            y_race = int(row[\"race_id\"])\n",
    "            return img, (y_age, y_gender, y_race)\n",
    "        else:\n",
    "            return img, row[\"image_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf0529-1cfc-45e9-be62-4752cc707678",
   "metadata": {},
   "source": [
    "Transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e237a83-1915-4ddb-8ff8-4cc9d569a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038d19d-57b9-4c7b-ba30-9521d8062401",
   "metadata": {},
   "source": [
    "Split A into train/val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c6ae3-a20b-4880-b56a-f25f522774da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Correct stratify column\n",
    "counts = dfA['gender'].value_counts()\n",
    "dfA_filtered = dfA[dfA['gender'].isin(counts[counts >= 2].index)]\n",
    "\n",
    "trainA, valA = train_test_split(\n",
    "    dfA_filtered,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dfA_filtered['gender']\n",
    ")\n",
    "\n",
    "ds_trainA = FaceDataset(trainA, transform=transform, has_demo_labels=True)\n",
    "ds_valA   = FaceDataset(valA, transform=transform, has_demo_labels=True)\n",
    "\n",
    "dl_trainA = DataLoader(ds_trainA, batch_size=32, shuffle=True, num_workers=2)\n",
    "dl_valA   = DataLoader(ds_valA, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df7b01-5550-4b0f-813c-85530b64c27a",
   "metadata": {},
   "source": [
    "# Step 4 — Define a multi-head demographics model (Age/Gender/Race)\n",
    "Use a pretrained backbone (ResNet18) + 3 classifier heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d2235-c1bb-47a4-b8f4-a55eb38b4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoNet(nn.Module):\n",
    "    def __init__(self, num_age, num_gender, num_race):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.head_age = nn.Linear(in_features, num_age)\n",
    "        self.head_gender = nn.Linear(in_features, num_gender)\n",
    "        self.head_race = nn.Linear(in_features, num_race)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return {\n",
    "            \"age\": self.head_age(feat),\n",
    "            \"gender\": self.head_gender(feat),\n",
    "            \"race\": self.head_race(feat)\n",
    "        }\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = DemoNet(num_age, num_gender, num_race).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac6d736-c789-4ff7-823c-418a64d40c76",
   "metadata": {},
   "source": [
    "Losses + optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f178d35-2b06-4f0a-afb4-55a24c1965b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb39731-24b0-46c7-858b-3833082501ed",
   "metadata": {},
   "source": [
    "# Step 5 — Train the demographics model on Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8d521-9e91-4d64-91d3-d2c5891bac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    correct = {\"age\":0, \"gender\":0, \"race\":0}\n",
    "    total = 0\n",
    "    for x, (y_age, y_gender, y_race) in dl:\n",
    "        x = x.to(device)\n",
    "        y_age = y_age.to(device)\n",
    "        y_gender = y_gender.to(device)\n",
    "        y_race = y_race.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        pred_age = out[\"age\"].argmax(1)\n",
    "        pred_gender = out[\"gender\"].argmax(1)\n",
    "        pred_race = out[\"race\"].argmax(1)\n",
    "\n",
    "        total += x.size(0)\n",
    "        correct[\"age\"] += (pred_age == y_age).sum().item()\n",
    "        correct[\"gender\"] += (pred_gender == y_gender).sum().item()\n",
    "        correct[\"race\"] += (pred_race == y_race).sum().item()\n",
    "\n",
    "    return {k: correct[k]/total for k in correct}\n",
    "\n",
    "def train_one_epoch(model, dl):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for x, (y_age, y_gender, y_race) in dl:\n",
    "        x = x.to(device)\n",
    "        y_age = y_age.to(device)\n",
    "        y_gender = y_gender.to(device)\n",
    "        y_race = y_race.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = ce(out[\"age\"], y_age) + ce(out[\"gender\"], y_gender) + ce(out[\"race\"], y_race)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running += loss.item() * x.size(0)\n",
    "\n",
    "    return running / len(dl.dataset)\n",
    "\n",
    "for epoch in range(5):\n",
    "    tr_loss = train_one_epoch(model, dl_trainA)\n",
    "    metrics = evaluate(model, dl_valA)\n",
    "    print(f\"Epoch {epoch+1}: loss={tr_loss:.4f} val_acc={metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abed238-8981-43de-890a-0c7275eb7854",
   "metadata": {},
   "source": [
    "# Step 6 — Infer pseudo-labels for Dataset B (emotion-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9feab-ce60-4cf0-b68d-8154228dd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_B = FaceDataset(dfB, transform=transform, has_demo_labels=False)\n",
    "dl_B = DataLoader(ds_B, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def pseudo_label_B(model, dl):\n",
    "    model.eval()\n",
    "    rows = []\n",
    "    for x, paths in tqdm(dl):\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "\n",
    "        p_age = softmax(out[\"age\"])\n",
    "        p_gender = softmax(out[\"gender\"])\n",
    "        p_race = softmax(out[\"race\"])\n",
    "\n",
    "        age_pred = p_age.argmax(1).cpu().numpy()\n",
    "        gender_pred = p_gender.argmax(1).cpu().numpy()\n",
    "        race_pred = p_race.argmax(1).cpu().numpy()\n",
    "\n",
    "        age_conf = p_age.max(1).values.cpu().numpy()\n",
    "        gender_conf = p_gender.max(1).values.cpu().numpy()\n",
    "        race_conf = p_race.max(1).values.cpu().numpy()\n",
    "\n",
    "        for path, a,g,r,ca,cg,cr in zip(paths, age_pred, gender_pred, race_pred, age_conf, gender_conf, race_conf):\n",
    "            rows.append({\n",
    "                \"image_path\": path,\n",
    "                \"age_pseudo\": int(a),\n",
    "                \"gender_pseudo\": int(g),\n",
    "                \"race_pseudo\": int(r),\n",
    "                \"age_conf\": float(ca),\n",
    "                \"gender_conf\": float(cg),\n",
    "                \"race_conf\": float(cr),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "dfB_pseudo = pseudo_label_B(model, dl_B)\n",
    "dfB_aug = dfB.merge(dfB_pseudo, on=r\"C:\\Users\\bensa\\Desktop\\ETUDES\\Deep Learning\\Project\\B.csv\", how=\"left\")\n",
    "dfB_aug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2274f-482e-4182-922a-e0f709b72385",
   "metadata": {},
   "source": [
    "# Step 7 — Confidence filtering (important!)\n",
    "You don’t want to treat low-confidence guesses as truth.\n",
    "\n",
    "Example: if confidence < 0.80, mark as unknown (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469349a3-ce66-457f-b1fa-3095e979c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.80\n",
    "\n",
    "for col, conf in [(\"age_pseudo\",\"age_conf\"), (\"gender_pseudo\",\"gender_conf\"), (\"race_pseudo\",\"race_conf\")]:\n",
    "    dfB_aug.loc[dfB_aug[conf] < TH, col] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2b2e5-34fe-47ff-9b1b-1cde8c39eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB_aug.to_csv(r\"C:\\Users\\bensa\\Desktop\\ETUDES\\Deep Learning\\Project\\B_with_pseudo_demographics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a993073-163c-4ae1-970c-917eea1ca92f",
   "metadata": {},
   "source": [
    "# Step 8 — Merge A + B into one unified dataset file\n",
    "Keep true labels separate from pseudo labels so you don’t confuse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544649a0-b0e7-488e-bf6c-bab392a39b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA_out = dfA.copy()\n",
    "dfA_out[\"emotion\"] = np.nan\n",
    "dfA_out[\"source\"] = \"A_true_demo\"\n",
    "dfA_out[\"age_true\"] = dfA_out[\"age_bin\"]\n",
    "dfA_out[\"gender_true\"] = dfA_out[\"gender_id\"]\n",
    "dfA_out[\"race_true\"] = dfA_out[\"race_id\"]\n",
    "\n",
    "dfA_out[\"age_pseudo\"] = np.nan\n",
    "dfA_out[\"gender_pseudo\"] = np.nan\n",
    "dfA_out[\"race_pseudo\"] = np.nan\n",
    "dfA_out[\"age_conf\"] = np.nan\n",
    "dfA_out[\"gender_conf\"] = np.nan\n",
    "dfA_out[\"race_conf\"] = np.nan\n",
    "\n",
    "dfB_out = dfB_aug.copy()\n",
    "dfB_out[\"source\"] = \"B_true_emotion\"\n",
    "dfB_out[\"age_true\"] = np.nan\n",
    "dfB_out[\"gender_true\"] = np.nan\n",
    "dfB_out[\"race_true\"] = np.nan\n",
    "\n",
    "# Make sure columns exist / align\n",
    "keep_cols = [\"image_path\",\"emotion\",\"source\",\n",
    "             \"age_true\",\"gender_true\",\"race_true\",\n",
    "             \"age_pseudo\",\"gender_pseudo\",\"race_pseudo\",\n",
    "             \"age_conf\",\"gender_conf\",\"race_conf\"]\n",
    "\n",
    "merged = pd.concat([dfA_out[keep_cols], dfB_out[keep_cols]], ignore_index=True)\n",
    "merged.to_csv(r\"C:\\Users\\bensa\\Desktop\\ETUDES\\Deep Learning\\Project\\merged_A_B.csv\", index=False)\n",
    "print(\"File save attempted\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68a705-8278-403f-afd7-abd609b47fef",
   "metadata": {},
   "source": [
    "# Step 9 — How you train after merging (key idea)\n",
    "\n",
    "When training a multi-task model later:\n",
    "\n",
    "If age_true exists → train age head with it\n",
    "\n",
    "Else if age_pseudo != -1 → optionally train with pseudo-label\n",
    "\n",
    "Else → skip age loss for that sample\n",
    "\n",
    "Same for gender/race.\n",
    "\n",
    "This is the right way to use the merged file without corrupting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70e557-8422-4a58-9a4a-3cc580aa068a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
